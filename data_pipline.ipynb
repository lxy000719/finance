{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from openbb import obb\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, Float\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy import inspect\n",
    "import yfinance as yf\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import ta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liuxingyu/project/finance/.venv\n",
      "/Users/liuxingyu/project/finance/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "# check environment\n",
    "print(sys.prefix)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_data(symbol, interval='1d', window1=3, window2=20, alpha1=0.1, alpha2=0.5):\n",
    "    # start_date and end_date default is 99 years and now if set none\n",
    "    data_historical = yf.download(symbol, interval=interval, period='max', actions='True')\n",
    "\n",
    "    # Calculate RSI\n",
    "    data_historical[\"RSI\"] = ta.momentum.RSIIndicator(data_historical[\"Close\"]).rsi()\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    bbands = ta.volatility.BollingerBands(data_historical[\"Close\"])\n",
    "    data_historical[\"BB_upper\"] = bbands.bollinger_hband()\n",
    "    data_historical[\"BB_lower\"] = bbands.bollinger_lband()\n",
    "\n",
    "    # Calculate MACD\n",
    "    macd = ta.trend.MACD(data_historical[\"Close\"])\n",
    "    data_historical[\"MACD\"] = macd.macd()\n",
    "    data_historical[\"MACD_signal\"] = macd.macd_signal()\n",
    "\n",
    "    # Calculate percentage change\n",
    "    data_historical['pct_change'] = data_historical['Adj Close'].pct_change()\n",
    "\n",
    "    # min_periods = 1 let the ma starting with first month\n",
    "    SMA1 = \"SMA-\"+str(window1)\n",
    "    data_historical[SMA1] = data_historical['Adj Close'].rolling(window1,min_periods=1).mean()\n",
    "\n",
    "    window = 20\n",
    "    SMA2 = \"SMA-\"+str(window2)\n",
    "    data_historical[SMA2] = data_historical['Adj Close'].rolling(window2,min_periods=1).mean()\n",
    "\n",
    "    data_historical['EMA_'+str(alpha1)] = data_historical['Adj Close'].ewm(alpha=alpha1, adjust=False).mean()\n",
    "    data_historical['EMA_'+str(alpha2)] = data_historical['Adj Close'].ewm(alpha=alpha2, adjust=False).mean()\n",
    "\n",
    "    # Shift to the future by one day so that everyday uses the information up to \n",
    "    # yesterday to make a trading decision for tmr\n",
    "    data_historical[SMA1+'-3_shift_1d'] = data_historical[SMA1].shift(1)\n",
    "    data_historical[SMA2+'-20_shift_1d'] = data_historical[SMA2].shift(1)\n",
    "\n",
    "    # identify buy signal\n",
    "    data_historical['signal'] = np.where(data_historical[SMA1+'-3_shift_1d'] > data_historical[SMA2+'-20_shift_1d'], 1, 0)\n",
    "    # identify sell signal\n",
    "    data_historical['signal'] = np.where(data_historical[SMA1+'-3_shift_1d'] < data_historical[SMA2+'-20_shift_1d'], -1, data_historical['signal'])\n",
    "\n",
    "    # calculate instantaneous log return for buy-and-hold straetegy as benchmark\n",
    "    data_historical['log_return_buy_n_hold'] = np.log(data_historical['Adj Close']).diff()\n",
    "\n",
    "    # calculate instantaneous log return for trend following straetegy\n",
    "    data_historical['log_return_trend_follow'] = data_historical['signal'] * data_historical['log_return_buy_n_hold']\n",
    "\n",
    "    # calculate the cumulative return for buy-and-hold and trend-following strategy\n",
    "    data_historical['return_buy_n_hold'] = np.exp(data_historical['log_return_buy_n_hold']).cumprod()\n",
    "    data_historical['return_trend_follow'] = np.exp(data_historical['log_return_trend_follow']).cumprod()\n",
    "\n",
    "    # derive trading action at each time step; 2 is buy, -2 is sell\n",
    "    data_historical['action'] = data_historical.signal.diff()\n",
    "\n",
    "    data_historical['symbol'] = symbol\n",
    "\n",
    "    return data_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_info(symbol):\n",
    "    ticker_obj = yf.Ticker(symbol)\n",
    "\n",
    "    # change format to meet the requirements of saving into mysql\n",
    "    ticker_obj.info['companyOfficers'] = json.dumps(ticker_obj.info['companyOfficers'])\n",
    "    \n",
    "    df_info = pd.DataFrame([ticker_obj.info])\n",
    "    df_info['symbol'] = symbol\n",
    "    df_actions = ticker_obj.actions.reset_index()\n",
    "    df_actions['symbol'] = symbol\n",
    "    df_quarterly_income_stmt = ticker_obj.quarterly_income_stmt.transpose().reset_index()\n",
    "    df_quarterly_income_stmt['symbol'] = symbol\n",
    "    df_quarterly_balance_sheet = ticker_obj.quarterly_balance_sheet.transpose().reset_index()\n",
    "    df_quarterly_balance_sheet['symbol'] = symbol\n",
    "    df_quarterly_cashflow = ticker_obj.quarterly_cashflow.transpose().reset_index()\n",
    "    df_quarterly_cashflow['symbol'] = symbol\n",
    "    df_recommendations_summary = ticker_obj.recommendations_summary\n",
    "    df_recommendations_summary['symbol'] = symbol\n",
    "    df_upgrades_downgrades = ticker_obj.upgrades_downgrades.reset_index()\n",
    "    df_upgrades_downgrades['symbol'] = symbol\n",
    "    df_get_earnings_dates = ticker_obj.get_earnings_dates(limit=1000).reset_index()\n",
    "    df_get_earnings_dates['symbol'] = symbol\n",
    "    df_news = pd.DataFrame(ticker_obj.news)\n",
    "    df_news['thumbnail'] = df_news['thumbnail'].apply(json.dumps)\n",
    "    df_news['relatedTickers'] = df_news['relatedTickers'].apply(json.dumps)\n",
    "    df_news['symbol'] = symbol\n",
    "\n",
    "    return df_info, df_actions, df_quarterly_income_stmt, df_quarterly_balance_sheet, df_quarterly_cashflow, df_recommendations_summary, \\\n",
    "    df_upgrades_downgrades, df_get_earnings_dates, df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "symbol_list = ['NVDA','TSLA','MSFT','AMZN','AAPL','META','GOOG']\n",
    "# symbol_list = ['NVDA']\n",
    "end_date = pd.Timestamp.now().tz_localize('Asia/Singapore').tz_convert('US/Eastern').strftime('%Y-%m-%d')\n",
    "start_date = '1900-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# initialise empty dataframes\n",
    "df_info_all = pd.DataFrame()\n",
    "df_actions_all = pd.DataFrame()\n",
    "df_quarterly_income_stmt_all = pd.DataFrame()\n",
    "df_quarterly_balance_sheet_all = pd.DataFrame()\n",
    "df_quarterly_cashflow_all = pd.DataFrame()\n",
    "df_recommendations_summary_all = pd.DataFrame()\n",
    "df_upgrades_downgrades_all = pd.DataFrame()\n",
    "df_get_earnings_dates_all = pd.DataFrame()\n",
    "df_news_all = pd.DataFrame()\n",
    "data_historical_all = pd.DataFrame()\n",
    "\n",
    "# save data for all symbols\n",
    "for symbol in symbol_list:\n",
    "    print(symbol)\n",
    "    df_info, df_actions, df_quarterly_income_stmt, df_quarterly_balance_sheet, df_quarterly_cashflow, df_recommendations_summary, \\\n",
    "    df_upgrades_downgrades, df_get_earnings_dates, df_news = general_info(symbol)\n",
    "    df_historical = historical_data(symbol, interval='1d', window1=3, window2=20, alpha1=0.1, alpha2=0.5).reset_index()\n",
    "    data_historical_all = pd.concat([data_historical_all, df_historical], ignore_index=True)\n",
    "    df_info_all = pd.concat([df_info_all, df_info], ignore_index=True)\n",
    "    df_actions_all = pd.concat([df_actions_all, df_actions], ignore_index=True)\n",
    "    df_quarterly_income_stmt_all = pd.concat([df_quarterly_income_stmt_all, df_quarterly_income_stmt], ignore_index=True)\n",
    "    df_quarterly_balance_sheet_all = pd.concat([df_quarterly_balance_sheet_all, df_quarterly_balance_sheet], ignore_index=True)\n",
    "    df_quarterly_cashflow_all = pd.concat([df_quarterly_cashflow_all, df_quarterly_cashflow], ignore_index=True)\n",
    "    df_recommendations_summary_all = pd.concat([df_recommendations_summary_all, df_recommendations_summary], ignore_index=True)\n",
    "    df_upgrades_downgrades_all = pd.concat([df_upgrades_downgrades_all, df_upgrades_downgrades], ignore_index=True)\n",
    "    df_get_earnings_dates_all = pd.concat([df_get_earnings_dates_all, df_get_earnings_dates], ignore_index=True)\n",
    "    df_news_all = pd.concat([df_news_all, df_news], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the connection URL\n",
    "# DATABASE_URL = \"mysql+mysqlconnector://root:Lxy930719@localhost/finance\"\n",
    "DATABASE_URL = \"mysql+mysqlconnector://lxy:Lxy930719~@mydb.cvgm8e2kwp95.us-east-1.rds.amazonaws.com/finance\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    df_info_all,\n",
    "    df_actions_all,\n",
    "    df_quarterly_income_stmt_all,\n",
    "    df_quarterly_balance_sheet_all,\n",
    "    df_quarterly_cashflow_all,\n",
    "    df_recommendations_summary_all,\n",
    "    df_upgrades_downgrades_all,\n",
    "    df_get_earnings_dates_all,\n",
    "    df_news_all,\n",
    "    data_historical_all\n",
    "    ]\n",
    "table_names = [\n",
    "    'stock_company_info',\n",
    "    'stock_actions',\n",
    "    'stock_quarterly_income_stmt',\n",
    "    'stock_quarterly_balance_sheet',\n",
    "    'stock_quarterly_cashflow',\n",
    "    'stock_recommendations_summary',\n",
    "    'stock_upgrades_downgrades',\n",
    "    'stock_get_earnings_dates',\n",
    "    'stock_news',\n",
    "    'stock_data_historical'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into table 'stock_company_info' successfully.\n",
      "Data inserted into table 'stock_actions' successfully.\n",
      "Data inserted into table 'stock_quarterly_income_stmt' successfully.\n",
      "Data inserted into table 'stock_quarterly_balance_sheet' successfully.\n",
      "Data inserted into table 'stock_quarterly_cashflow' successfully.\n",
      "Data inserted into table 'stock_recommendations_summary' successfully.\n",
      "Data inserted into table 'stock_upgrades_downgrades' successfully.\n",
      "Data inserted into table 'stock_get_earnings_dates' successfully.\n",
      "Data inserted into table 'stock_news' successfully.\n",
      "Data inserted into table 'stock_data_historical' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Insert dataframes into tables\n",
    "for table_name, df in zip(table_names, tables):\n",
    "    try:\n",
    "        # Write the DataFrame to the MySQL table\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        print(f\"Data inserted into table '{table_name}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into table '{table_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to local csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in excel table 'stock_company_info' successfully.\n",
      "Data saved in excel table 'stock_actions' successfully.\n",
      "Data saved in excel table 'stock_quarterly_income_stmt' successfully.\n",
      "Data saved in excel table 'stock_quarterly_balance_sheet' successfully.\n",
      "Data saved in excel table 'stock_quarterly_cashflow' successfully.\n",
      "Data saved in excel table 'stock_recommendations_summary' successfully.\n",
      "Data saved in excel table 'stock_upgrades_downgrades' successfully.\n",
      "Data saved in excel table 'stock_get_earnings_dates' successfully.\n",
      "Data saved in excel table 'stock_news' successfully.\n",
      "Data saved in excel table 'stock_data_historical' successfully.\n"
     ]
    }
   ],
   "source": [
    "for table_name, df in zip(table_names, tables):\n",
    "    try:\n",
    "        df.to_csv(f'./result/{table_name}.csv', index=False)\n",
    "        print(f\"Data saved in excel table '{table_name}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saved in excel table '{table_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
